# CS3640-A3

- Payton's Git: https://research-git.uiowa.edu/plovn/cs3640-a5
- Jason's Git: https://research-git.uiowa.edu/jsessler/cs3640-a5

## Resources Used:
- https://stackoverflow.com/questions/6168260/how-to-parse-a-url: helped understand how to parse URLs
- https://easylist.to/: using the adblocker provided by EasyList.
- https://stackoverflow.com/questions/15754208/how-to-make-argument-optional-in-python-argparse: understanding how to make an argument optional
- https://docs.python.org/3/library/urllib.parse.html: Documentation used for urlparser
- https://stackoverflow.com/questions/53992694/what-does-netloc-mean: answers question for what netloc is for urllib.parse
- https://www.selenium.dev/documentation/webdriver/: documentation for webdriver.
- https://www.geeksforgeeks.org/how-to-read-from-a-file-in-python/: how to read txt files when coding in python.



## Credits

### Work from Payton Lovan: 
- Worked on research paper
- Worked on researching needed modules
- Helped with implementing Adblocker to webcrawler function
- Initialized functions website_crawler_with_adblocker and load_adblock_rules
- Implemented an optional use of .txt file or using a singular URL link.
- Worked on implementing the relevant search for user inputs.


### Work from Noah Lawrence: 
- Worked on research paper
- Work on is_valid_url function
- Work on debugging
- Worked on documentation
- Gave an idea that a website needs to load for the script to run.
- Worked on implementing the relevant search for user inputs

### Work from Jason Sessler:
- Worked on research paper
- Worked on Edge case for webcrawler 
- Work on process_websites_from_file
- Worked on the argparse in the script
- Worked on debugging the count of the Total Links
- Implemented comparison of how to tell if it's a subdomain or a third-party link.

### Link to Doc: https://docs.google.com/document/d/1UiCdokXPPodHriBgHYKsXM3Ocyhxtq1Aq_H10Hn9pqg/edit?usp=sharing
